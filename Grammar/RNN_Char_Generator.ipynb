{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于RNN 的字符生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN](../Docs/RNN-Core.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 困惑度\n",
    "通常使用困惑度（complexity）来评价语言模型的好坏。\n",
    "\n",
    "**困惑度是对交叉损失函数做指数运算后得到的值。**\n",
    "\n",
    "**任何一个有效模型的困惑度必须小于类别个数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import zipfile\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import utils as d2l\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTokenizer(object):\n",
    "    def __init__(self, text=None, max_vocab=None, filename=None):\n",
    "        if filename is not None:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.vocab = pickle.load(f)\n",
    "        else:\n",
    "            corpus_chars = set(text)\n",
    "            # max_vocab_process\n",
    "            vocab_count = {}\n",
    "            for word in corpus_chars:\n",
    "                if vocab_count.get(word) is None:\n",
    "                    vocab_count[word] = 1\n",
    "                else:\n",
    "                    vocab_count[word] += 1\n",
    "\n",
    "            vocab_count_list = []\n",
    "            for word in vocab_count:\n",
    "                vocab_count_list.append((word, vocab_count[word]))\n",
    "            # sort count with number\n",
    "            vocab_count_list.sort(key=lambda x: x[1], reverse=True)\n",
    "            if max_vocab is not None and len(vocab_count_list) > max_vocab:\n",
    "                vocab_count_list = vocab_count_list[:max_vocab]\n",
    "            vocab = [x[0] for x in vocab_count_list]\n",
    "            self.vocab = vocab\n",
    "\n",
    "        self.char_to_index = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.index_to_char = dict(enumerate(self.vocab))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab) + 1\n",
    "\n",
    "    def word_to_index(self, word):\n",
    "        if word in self.char_to_index:\n",
    "            return self.char_to_index[word]\n",
    "        else:\n",
    "            return len(self.vocab)\n",
    "\n",
    "    def index_to_word(self, index):\n",
    "        if index == len(self.vocab):\n",
    "            return '<unk>'\n",
    "        elif index < len(self.vocab):\n",
    "            return self.char_to_index[index]\n",
    "        else:\n",
    "            raise Exception('Unknown index!')\n",
    "\n",
    "    def text_to_array(self, text):\n",
    "        arr = []\n",
    "        for word in text:\n",
    "            arr.append(self.word_to_index(word))\n",
    "        return np.array(arr)\n",
    "\n",
    "    def array_to_text(self, arr):\n",
    "        words = []\n",
    "        for index in arr:\n",
    "            words.append(self.index_to_word(index))\n",
    "        return \"\".join(words)\n",
    "\n",
    "    def save_to_file(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_random(corpus_indices, seq_length, time_steps, device=None):\n",
    "    num_samples = (len(corpus_indices) - 1) // time_steps\n",
    "    epoch_size = num_samples // seq_length\n",
    "\n",
    "    # shuffle sample\n",
    "    samples_indices = list(range(num_samples))\n",
    "    random.shuffle(samples_indices)\n",
    "\n",
    "    # generator data\n",
    "    for i in range(epoch_size):\n",
    "        i = i * seq_length\n",
    "\n",
    "        batch_incices = samples_indices[i: i + seq_length]\n",
    "        x = [corpus_indices[indices: indices + time_steps] for indices in batch_incices]\n",
    "        y = [corpus_indices[indices + 1: indices + time_steps + 1] for indices in batch_incices]\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float32).view(seq_length, time_steps)\n",
    "        y = torch.tensor(y, dtype=torch.float32).view(seq_length, time_steps)\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_consecutive(corpus_indices, seq_length, time_steps):\n",
    "\n",
    "    data_len = len(corpus_indices)\n",
    "\n",
    "    seq_size = data_len // seq_length\n",
    "\n",
    "    # resize to => (seq_length, seq_size)\n",
    "    corpus_indices = np.array(corpus_indices[: seq_size * seq_length], dtype=np.float).reshape((seq_length, -1))\n",
    "\n",
    "    epoch_size = (seq_size - 1) // time_steps\n",
    "\n",
    "    # generator data\n",
    "    np.random.shuffle(corpus_indices)\n",
    "\n",
    "    # convert to torch tensor\n",
    "    torch_indices = torch.tensor(corpus_indices, dtype=torch.float32).view(seq_length, seq_size)\n",
    "    for i in range(epoch_size):\n",
    "        i = i * time_steps\n",
    "        x = torch_indices[:, i: i + time_steps]\n",
    "        y = torch_indices[:, i + 1: i + time_steps + 1]\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('../Datasets/jaychou_lyrics/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read().decode('utf-8')  # corpus\n",
    "\n",
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\t', ' ')\n",
    "corpus_chars = corpus_chars[: 20000]\n",
    "\n",
    "tokenizer = TextTokenizer(text=corpus_chars, max_vocab=None)\n",
    "\n",
    "vocab = tokenizer.vocab\n",
    "char_to_index = tokenizer.char_to_index\n",
    "index_to_char = tokenizer.index_to_char\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "corpus_indices = tokenizer.text_to_array(corpus_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1448])\n"
     ]
    }
   ],
   "source": [
    "def onehot(X, n_class):\n",
    "    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\n",
    "\n",
    "    return [F.one_hot(X[:, i].to(torch.int64), n_class).to(dtype=torch.float32, device=device) for i in range(X.shape[1])]\n",
    "\n",
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print('will use', device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = _one((num_inputs, num_hiddens))\n",
    "    W_hh = _one((num_hiddens, num_hiddens))\n",
    "    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device), requires_grad=True)\n",
    "    # 输出层参数\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device), requires_grad=True)\n",
    "    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(seq_length, num_hiddens, device):\n",
    "    return (torch.zeros((seq_length, num_hiddens), device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs和outputs皆为num_steps个形状为(seq_length, vocab_size)的矩阵\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n",
    "        Y = torch.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1448])\n",
      "5 torch.Size([2, 1448]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(10).view(2, 5)\n",
    "state = init_rnn_state(X.shape[0], num_hiddens, device)\n",
    "inputs = onehot(X.to(device), vocab_size)\n",
    "print(inputs[0].size())\n",
    "params = get_params()\n",
    "outputs, state_new = rnn(inputs, state, params)\n",
    "print(len(outputs), outputs[0].shape, state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device):\n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta / norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n",
    "                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\n",
    "    state = init_rnn_state(1, num_hiddens, device)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        # 将上一时间步的输出作为当前时间步的输入\n",
    "        X = onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\n",
    "        # 计算输出和更新隐藏状态\n",
    "        (Y, state) = rnn(X, state, params)\n",
    "        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分开胖敌奔听役嘲凝呆u箭\n"
     ]
    }
   ],
   "source": [
    "p = predict_rnn('分开', 10, rnn, params, init_rnn_state, num_hiddens, vocab_size,\n",
    "                    device, index_to_char, char_to_index)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                          vocab_size, device, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, is_random_iter, num_epochs, num_steps,\n",
    "                          lr, clipping_theta, seq_length, pred_period,\n",
    "                          pred_len, prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = d2l.data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = d2l.data_iter_consecutive\n",
    "    params = get_params()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\n",
    "            state = init_rnn_state(seq_length, num_hiddens, device)\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_fn(corpus_indices, seq_length, num_steps, device)\n",
    "        for X, Y in data_iter:\n",
    "            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\n",
    "                state = init_rnn_state(seq_length, num_hiddens, device)\n",
    "            else:\n",
    "                # 否则需要使用detach函数从计算图分离隐藏状态, 这是为了\n",
    "                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "\n",
    "            inputs = onehot(X, vocab_size)\n",
    "            # outputs有num_steps个形状为(seq_length, vocab_size)的矩阵\n",
    "            (outputs, state) = rnn(inputs, state, params)\n",
    "            # 拼接之后形状为(num_steps * seq_length, vocab_size)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            # Y的形状是(seq_length, num_steps)，转置后再变成长度为\n",
    "            # batch * num_steps 的向量，这样跟输出的行一一对应\n",
    "            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "            # 使用交叉熵损失计算平均分类误差\n",
    "            l = loss(outputs, y.long())\n",
    "\n",
    "            # 梯度清0\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n",
    "            d2l.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "                epoch + 1, math.exp(l_sum / n), time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n",
    "                                        num_hiddens, vocab_size, device, idx_to_char, char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, perplexity 50.137844, time 2.02 sec\n",
      " - 分开 我想要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我不要再想 我\n",
      " - 不分开  没有你不是我 说你的微我面狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏\n",
      "epoch 100, perplexity 7.507939, time 2.46 sec\n",
      " - 分开 一直在人向 我有往 你在我 我想就你陪远的话火  眼括风木的半  我想你也表开的 不是问你的想这种\n",
      " - 不分开简 我不能再想 我不 我不 我不要再想 我不 我不 我不要再想 我不 我不 我不要再想 我不 我不 \n",
      "epoch 150, perplexity 3.362050, time 0.25 sec\n",
      " - 分开 我说不起你牵着你的手不放开 爱可不能够永远单单没有悲哀 我 想带你骑单车 我 想和你看棒的 我用 \n",
      " - 不分开吗 我后能再想 我的没有 情笑是从后棍 我右拳打开了天 化身为龙 把山地重新移动 填平裂缝 全东方 \n",
      "epoch 200, perplexity 2.387300, time 0.23 sec\n",
      " - 分开 我只会这开牵 我的想爸分 我的天空 你爱是有了中干 包间裂撑的泥土 不会在染的转征 然后上白的象多\n",
      " - 不分开时样 所以你弃过 所以你弃权 我们一口好酒我 爬因为我 说你已经太 不手不觉 我 将笑开的注球 你在\n",
      "epoch 250, perplexity 2.145181, time 0.24 sec\n",
      " - 分开 我说好这样牵 天涯尽是 又轻如一切秋的日场  否在风此的背号  才有你依之 这种多久太妈你 你不想\n",
      " - 不分开时样 我以你能不见 我不会掩想你 不知不觉 你已经离开我 不知不觉 我看了这节奏 后知后觉 后知后觉\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, seq_length, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "\n",
    "train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                      vocab_size, device, corpus_indices, index_to_char,\n",
    "                      char_to_index, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, seq_length, pred_period, pred_len,\n",
    "                      prefixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
