{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import zipfile\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import utils as d2l\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTokenizer(object):\n",
    "    def __init__(self, text=None, max_vocab=None, filename=None):\n",
    "        if filename is not None:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.vocab = pickle.load(f)\n",
    "        else:\n",
    "            corpus_chars = set(text)\n",
    "            # max_vocab_process\n",
    "            vocab_count = {}\n",
    "            for word in corpus_chars:\n",
    "                if vocab_count.get(word) is None:\n",
    "                    vocab_count[word] = 1\n",
    "                else:\n",
    "                    vocab_count[word] += 1\n",
    "\n",
    "            vocab_count_list = []\n",
    "            for word in vocab_count:\n",
    "                vocab_count_list.append((word, vocab_count[word]))\n",
    "            # sort count with number\n",
    "            vocab_count_list.sort(key=lambda x: x[1], reverse=True)\n",
    "            if max_vocab is not None and len(vocab_count_list) > max_vocab:\n",
    "                vocab_count_list = vocab_count_list[:max_vocab]\n",
    "            vocab = [x[0] for x in vocab_count_list]\n",
    "            self.vocab = vocab\n",
    "\n",
    "        self.char_to_index = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.index_to_char = dict(enumerate(self.vocab))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab) + 1\n",
    "\n",
    "    def word_to_index(self, word):\n",
    "        if word in self.char_to_index:\n",
    "            return self.char_to_index[word]\n",
    "        else:\n",
    "            return len(self.vocab)\n",
    "\n",
    "    def index_to_word(self, index):\n",
    "        if index == len(self.vocab):\n",
    "            return '<unk>'\n",
    "        elif index < len(self.vocab):\n",
    "            return self.char_to_index[index]\n",
    "        else:\n",
    "            raise Exception('Unknown index!')\n",
    "\n",
    "    def text_to_array(self, text):\n",
    "        arr = []\n",
    "        for word in text:\n",
    "            arr.append(self.word_to_index(word))\n",
    "        return np.array(arr)\n",
    "\n",
    "    def array_to_text(self, arr):\n",
    "        words = []\n",
    "        for index in arr:\n",
    "            words.append(self.index_to_word(index))\n",
    "        return \"\".join(words)\n",
    "\n",
    "    def save_to_file(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_random(corpus_indices, seq_length, time_steps, device=None):\n",
    "    num_samples = (len(corpus_indices) - 1) // time_steps\n",
    "    epoch_size = num_samples // seq_length\n",
    "\n",
    "    # shuffle sample\n",
    "    samples_indices = list(range(num_samples))\n",
    "    random.shuffle(samples_indices)\n",
    "\n",
    "    # generator data\n",
    "    for i in range(epoch_size):\n",
    "        i = i * seq_length\n",
    "\n",
    "        batch_incices = samples_indices[i: i + seq_length]\n",
    "        x = [corpus_indices[indices: indices + time_steps] for indices in batch_incices]\n",
    "        y = [corpus_indices[indices + 1: indices + time_steps + 1] for indices in batch_incices]\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float32).view(seq_length, time_steps)\n",
    "        y = torch.tensor(y, dtype=torch.float32).view(seq_length, time_steps)\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_consecutive(corpus_indices, seq_length, time_steps):\n",
    "\n",
    "    data_len = len(corpus_indices)\n",
    "\n",
    "    seq_size = data_len // seq_length\n",
    "\n",
    "    # resize to => (seq_length, seq_size)\n",
    "    corpus_indices = np.array(corpus_indices[: seq_size * seq_length], dtype=np.float).reshape((seq_length, -1))\n",
    "\n",
    "    epoch_size = (seq_size - 1) // time_steps\n",
    "\n",
    "    # generator data\n",
    "    np.random.shuffle(corpus_indices)\n",
    "\n",
    "    # convert to torch tensor\n",
    "    torch_indices = torch.tensor(corpus_indices, dtype=torch.float32).view(seq_length, seq_size)\n",
    "    for i in range(epoch_size):\n",
    "        i = i * time_steps\n",
    "        x = torch_indices[:, i: i + time_steps]\n",
    "        y = torch_indices[:, i + 1: i + time_steps + 1]\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('../Datasets/jaychou_lyrics/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read().decode('utf-8')  # corpus\n",
    "\n",
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\t', ' ')\n",
    "corpus_chars = corpus_chars[: 20000]\n",
    "\n",
    "tokenizer = TextTokenizer(text=corpus_chars, max_vocab=None)\n",
    "\n",
    "vocab = tokenizer.vocab\n",
    "char_to_index = tokenizer.char_to_index\n",
    "index_to_char = tokenizer.index_to_char\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "corpus_indices = tokenizer.text_to_array(corpus_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1448])\n"
     ]
    }
   ],
   "source": [
    "def onehot(X, n_class):\n",
    "    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\n",
    "\n",
    "    return [F.one_hot(X[:, i].to(torch.int64), n_class).to(dtype=torch.float32, device=device) for i in range(X.shape[1])]\n",
    "\n",
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print('will use', device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = _one((num_inputs, num_hiddens))\n",
    "    W_hh = _one((num_hiddens, num_hiddens))\n",
    "    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device), requires_grad=True)\n",
    "    # 输出层参数\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device), requires_grad=True)\n",
    "    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(seq_length, num_hiddens, device):\n",
    "    return (torch.zeros((seq_length, num_hiddens), device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs和outputs皆为num_steps个形状为(seq_length, vocab_size)的矩阵\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n",
    "        Y = torch.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1448])\n",
      "5 torch.Size([2, 1448]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(10).view(2, 5)\n",
    "state = init_rnn_state(X.shape[0], num_hiddens, device)\n",
    "inputs = onehot(X.to(device), vocab_size)\n",
    "print(inputs[0].size())\n",
    "params = get_params()\n",
    "outputs, state_new = rnn(inputs, state, params)\n",
    "print(len(outputs), outputs[0].shape, state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device):\n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta / norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n",
    "                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\n",
    "    state = init_rnn_state(1, num_hiddens, device)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        # 将上一时间步的输出作为当前时间步的输入\n",
    "        X = onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\n",
    "        # 计算输出和更新隐藏状态\n",
    "        (Y, state) = rnn(X, state, params)\n",
    "        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分开芜礼拥但祟,补排伫弟\n"
     ]
    }
   ],
   "source": [
    "p = predict_rnn('分开', 10, rnn, params, init_rnn_state, num_hiddens, vocab_size,\n",
    "                    device, index_to_char, char_to_index)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                          vocab_size, device, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, is_random_iter, num_epochs, num_steps,\n",
    "                          lr, clipping_theta, seq_length, pred_period,\n",
    "                          pred_len, prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = d2l.data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = d2l.data_iter_consecutive\n",
    "    params = get_params()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\n",
    "            state = init_rnn_state(seq_length, num_hiddens, device)\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_fn(corpus_indices, seq_length, num_steps, device)\n",
    "        for X, Y in data_iter:\n",
    "            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\n",
    "                state = init_rnn_state(seq_length, num_hiddens, device)\n",
    "            else:\n",
    "                # 否则需要使用detach函数从计算图分离隐藏状态, 这是为了\n",
    "                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "\n",
    "            inputs = onehot(X, vocab_size)\n",
    "            # outputs有num_steps个形状为(seq_length, vocab_size)的矩阵\n",
    "            (outputs, state) = rnn(inputs, state, params)\n",
    "            # 拼接之后形状为(num_steps * seq_length, vocab_size)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            # Y的形状是(seq_length, num_steps)，转置后再变成长度为\n",
    "            # batch * num_steps 的向量，这样跟输出的行一一对应\n",
    "            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "            # 使用交叉熵损失计算平均分类误差\n",
    "            l = loss(outputs, y.long())\n",
    "\n",
    "            # 梯度清0\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n",
    "            d2l.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "                epoch + 1, math.exp(l_sum / n), time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n",
    "                                        num_hiddens, vocab_size, device, idx_to_char, char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, perplexity 49.276773, time 0.23 sec\n",
      " - 分开 我想要再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我\n",
      " - 不分开 我只想这生 我不要再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我\n",
      "epoch 100, perplexity 7.332954, time 0.26 sec\n",
      " - 分开 我有一起稚奏过 化身为龙 把山河 的日情只剩下一种 等待英雄 我就是那条龙 哼哼哈兮 快使用双截棍\n",
      " - 不分开 我知道这样更 后知后觉 不知跳动 在一身好 记一定两 我有没有 你一定好 泪边不同 你不懂  一场\n",
      "epoch 150, perplexity 3.305624, time 0.24 sec\n",
      " - 分开 我有不能生活的脸 随时事都来袭知平 爷爷泡午的邪吻树苗空 等板小心了在的街 有一事味现叫的家 陆什\n",
      " - 不分开吗 我后你好去你 爱情你的多球 那檐没对医 用化的没有你说的雨生 现铁到一步都的街晨  何多却的出笑\n",
      "epoch 200, perplexity 2.405658, time 0.23 sec\n",
      " - 分开 没有不用担着我进攻 我的伤口你 单没的距离 是你的侧脸倒在我的怀里 你慢慢睡去 我摇不醒你 泪水在\n",
      " - 不分开 我只有这种弃 你知后觉 我该好好生活 我知不觉生活 我留着陪你 强忍着距滴里不了堤 W成在抽着始过\n",
      "epoch 250, perplexity 2.172886, time 0.22 sec\n",
      " - 分开 没有一直事  我该着这不要 你的将说开太 爱着不起 还就了一个秋 后知后觉 我该好好生活 我该好好\n",
      " - 不分开吗 然后将过去 慢慢到了天 仙在西元前 周杰横 它怪空 是属于我说心开 干 说录梦不是由 平以不说 \n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, seq_length, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "\n",
    "train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                      vocab_size, device, corpus_indices, index_to_char,\n",
    "                      char_to_index, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, seq_length, pred_period, pred_len,\n",
    "                      prefixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
