{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于RNN 的字符生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN](../Docs/RNN-Core.png)\n",
    "\n",
    "* 更新隐藏状态\n",
    "$$\\boldsymbol{H}t = \\phi(\\boldsymbol{X}t \\boldsymbol{W}{xh} + \\boldsymbol{H}{t-1} \\boldsymbol{W}_{hh} + \\boldsymbol{b}_h).$$\n",
    "\n",
    "* 计算输出\n",
    "$$\\boldsymbol{O}_t = \\boldsymbol{H}t \\boldsymbol{W}{hq} + \\boldsymbol{b}_q.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 困惑度\n",
    "通常使用困惑度（complexity）来评价语言模型的好坏。\n",
    "\n",
    "**困惑度是对交叉损失函数做指数运算后得到的值。**\n",
    "\n",
    "**任何一个有效模型的困惑度必须小于类别个数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import zipfile\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import utils as d2l\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTokenizer(object):\n",
    "    def __init__(self, text=None, max_vocab=None, filename=None):\n",
    "        if filename is not None:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.vocab = pickle.load(f)\n",
    "        else:\n",
    "            corpus_chars = set(text)\n",
    "            # max_vocab_process\n",
    "            vocab_count = {}\n",
    "            for word in corpus_chars:\n",
    "                if vocab_count.get(word) is None:\n",
    "                    vocab_count[word] = 1\n",
    "                else:\n",
    "                    vocab_count[word] += 1\n",
    "\n",
    "            vocab_count_list = []\n",
    "            for word in vocab_count:\n",
    "                vocab_count_list.append((word, vocab_count[word]))\n",
    "            # sort count with number\n",
    "            vocab_count_list.sort(key=lambda x: x[1], reverse=True)\n",
    "            if max_vocab is not None and len(vocab_count_list) > max_vocab:\n",
    "                vocab_count_list = vocab_count_list[:max_vocab]\n",
    "            vocab = [x[0] for x in vocab_count_list]\n",
    "            self.vocab = vocab\n",
    "\n",
    "        self.char_to_index = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.index_to_char = dict(enumerate(self.vocab))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab) + 1\n",
    "\n",
    "    def word_to_index(self, word):\n",
    "        if word in self.char_to_index:\n",
    "            return self.char_to_index[word]\n",
    "        else:\n",
    "            return len(self.vocab)\n",
    "\n",
    "    def index_to_word(self, index):\n",
    "        if index == len(self.vocab):\n",
    "            return '<unk>'\n",
    "        elif index < len(self.vocab):\n",
    "            return self.char_to_index[index]\n",
    "        else:\n",
    "            raise Exception('Unknown index!')\n",
    "\n",
    "    def text_to_array(self, text):\n",
    "        arr = []\n",
    "        for word in text:\n",
    "            arr.append(self.word_to_index(word))\n",
    "        return np.array(arr)\n",
    "\n",
    "    def array_to_text(self, arr):\n",
    "        words = []\n",
    "        for index in arr:\n",
    "            words.append(self.index_to_word(index))\n",
    "        return \"\".join(words)\n",
    "\n",
    "    def save_to_file(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_random(corpus_indices, seq_length, time_steps, device=None):\n",
    "    num_samples = (len(corpus_indices) - 1) // time_steps\n",
    "    epoch_size = num_samples // seq_length\n",
    "\n",
    "    # shuffle sample\n",
    "    samples_indices = list(range(num_samples))\n",
    "    random.shuffle(samples_indices)\n",
    "\n",
    "    # generator data\n",
    "    for i in range(epoch_size):\n",
    "        i = i * seq_length\n",
    "\n",
    "        batch_incices = samples_indices[i: i + seq_length]\n",
    "        x = [corpus_indices[indices: indices + time_steps] for indices in batch_incices]\n",
    "        y = [corpus_indices[indices + 1: indices + time_steps + 1] for indices in batch_incices]\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float32).view(seq_length, time_steps)\n",
    "        y = torch.tensor(y, dtype=torch.float32).view(seq_length, time_steps)\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_consecutive(corpus_indices, seq_length, time_steps):\n",
    "\n",
    "    data_len = len(corpus_indices)\n",
    "\n",
    "    seq_size = data_len // seq_length\n",
    "\n",
    "    # resize to => (seq_length, seq_size)\n",
    "    corpus_indices = np.array(corpus_indices[: seq_size * seq_length], dtype=np.float).reshape((seq_length, -1))\n",
    "\n",
    "    epoch_size = (seq_size - 1) // time_steps\n",
    "\n",
    "    # generator data\n",
    "    np.random.shuffle(corpus_indices)\n",
    "\n",
    "    # convert to torch tensor\n",
    "    torch_indices = torch.tensor(corpus_indices, dtype=torch.float32).view(seq_length, seq_size)\n",
    "    for i in range(epoch_size):\n",
    "        i = i * time_steps\n",
    "        x = torch_indices[:, i: i + time_steps]\n",
    "        y = torch_indices[:, i + 1: i + time_steps + 1]\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('../Datasets/jaychou_lyrics/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read().decode('utf-8')  # corpus\n",
    "\n",
    "corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\t', ' ')\n",
    "corpus_chars = corpus_chars[: 20000]\n",
    "\n",
    "tokenizer = TextTokenizer(text=corpus_chars, max_vocab=None)\n",
    "\n",
    "vocab = tokenizer.vocab\n",
    "char_to_index = tokenizer.char_to_index\n",
    "index_to_char = tokenizer.index_to_char\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "corpus_indices = tokenizer.text_to_array(corpus_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1448])\n"
     ]
    }
   ],
   "source": [
    "def onehot(X, n_class):\n",
    "    # X shape: (batch, seq_len), output: seq_len elements of (batch, n_class)\n",
    "\n",
    "    return [F.one_hot(X[:, i].to(torch.int64), n_class).to(dtype=torch.float32, device=device) for i in range(X.shape[1])]\n",
    "\n",
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n",
    "print('will use', device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts, requires_grad=True)\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = _one((num_inputs, num_hiddens))\n",
    "    W_hh = _one((num_hiddens, num_hiddens))\n",
    "    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device), requires_grad=True)\n",
    "    # 输出层参数\n",
    "    W_hq = _one((num_hiddens, num_outputs))\n",
    "    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device), requires_grad=True)\n",
    "    return nn.ParameterList([W_xh, W_hh, b_h, W_hq, b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(seq_length, num_hiddens, device):\n",
    "    return (torch.zeros((seq_length, num_hiddens), device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs和outputs皆为num_steps个形状为(seq_length, vocab_size)的矩阵\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n",
    "        Y = torch.matmul(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1448])\n",
      "5 torch.Size([2, 1448]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(10).view(2, 5)\n",
    "state = init_rnn_state(X.shape[0], num_hiddens, device)\n",
    "inputs = onehot(X.to(device), vocab_size)\n",
    "print(inputs[0].size())\n",
    "params = get_params()\n",
    "outputs, state_new = rnn(inputs, state, params)\n",
    "print(len(outputs), outputs[0].shape, state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, device):\n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta / norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n",
    "                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\n",
    "    state = init_rnn_state(1, num_hiddens, device)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        # 将上一时间步的输出作为当前时间步的输入\n",
    "        X = onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\n",
    "        # 计算输出和更新隐藏状态\n",
    "        (Y, state) = rnn(X, state, params)\n",
    "        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分开瓜拿存稳任坛探右力丁\n"
     ]
    }
   ],
   "source": [
    "p = predict_rnn('分开', 10, rnn, params, init_rnn_state, num_hiddens, vocab_size,\n",
    "                    device, index_to_char, char_to_index)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                          vocab_size, device, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, is_random_iter, num_epochs, num_steps,\n",
    "                          lr, clipping_theta, seq_length, pred_period,\n",
    "                          pred_len, prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = d2l.data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = d2l.data_iter_consecutive\n",
    "    params = get_params()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\n",
    "            state = init_rnn_state(seq_length, num_hiddens, device)\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_fn(corpus_indices, seq_length, num_steps, device)\n",
    "        for X, Y in data_iter:\n",
    "            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\n",
    "                state = init_rnn_state(seq_length, num_hiddens, device)\n",
    "            else:\n",
    "                # 否则需要使用detach函数从计算图分离隐藏状态, 这是为了\n",
    "                # 使模型参数的梯度计算只依赖一次迭代读取的小批量序列(防止梯度计算开销太大)\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "\n",
    "            inputs = onehot(X, vocab_size)\n",
    "            # outputs有num_steps个形状为(seq_length, vocab_size)的矩阵\n",
    "            (outputs, state) = rnn(inputs, state, params)\n",
    "            # 拼接之后形状为(num_steps * seq_length, vocab_size)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            # Y的形状是(seq_length, num_steps)，转置后再变成长度为\n",
    "            # batch * num_steps 的向量，这样跟输出的行一一对应\n",
    "            y = torch.transpose(Y, 0, 1).contiguous().view(-1)\n",
    "            # 使用交叉熵损失计算平均分类误差\n",
    "            l = loss(outputs, y.long())\n",
    "\n",
    "            # 梯度清0\n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n",
    "            d2l.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n",
    "            l_sum += l.item() * y.shape[0]\n",
    "            n += y.shape[0]\n",
    "\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "                epoch + 1, math.exp(l_sum / n), time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n",
    "                                        num_hiddens, vocab_size, device, idx_to_char, char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, perplexity 49.369783, time 0.22 sec\n",
      " - 分开 一直两步 我们了 一步两颗三步四颗 等天我们著的可 一直走剧 全小了空 在有了空 在在用空 在人用\n",
      " - 不分开 我只想起 你只会感到更加沮 别想我 别怪我 娘着我 单的我 别过 化什么 有什么  什么这样 我们\n",
      "epoch 100, perplexity 7.568152, time 0.26 sec\n",
      " - 分开 一直好气 快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 快使用双截棍 哼哼哈兮 快使用双截棍 哼\n",
      " - 不分开不能信天我 等不休我 爱你不能球更 爱天 他的古口 我想要回 你去的美 你知道 别不去 别影我的地球\n",
      "epoch 150, perplexity 3.247775, time 0.25 sec\n",
      " - 分开 你以想要多了离开还就为 远和的世 已吹的日尘 用制的神乐多 我会想到你小 我爱不起 我知之好生活 \n",
      " - 不分开不要一天 从故的眼我面狂的可爱女人 温柔的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯\n",
      "epoch 200, perplexity 2.319744, time 0.24 sec\n",
      " - 分开 单彻安 半什么 娘时了纳手代刚 干什么 干什么 想沉丹任手球真 干什么 干什么 想沉开任手球将 干\n",
      " - 不分开不 我想要再想 我不 我不 我不要再想你 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 250, perplexity 2.092166, time 0.25 sec\n",
      " - 分开 单水就能们 我对悔远控 黑云在降落 我被它拖着走 为我会想睡难 别隔壁对板 有天让 古着 只烟为久\n",
      " - 不分开吗 我叫在再想 他不能逃妥 一朵事他 温暖下人觉 白色蜡习 温暖的背尘 银制茶壶 在回村 废墟的风牺\n"
     ]
    }
   ],
   "source": [
    "num_epochs, num_steps, seq_length, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "\n",
    "train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                      vocab_size, device, corpus_indices, index_to_char,\n",
    "                      char_to_index, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, seq_length, pred_period, pred_len,\n",
    "                      prefixes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
