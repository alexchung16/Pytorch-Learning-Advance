{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 丢弃法\n",
    "\n",
    "* 丢弃法（dropout）方法主要用来应对深度学习中过拟合问题\n",
    "* dropout 只在训练时使用\n",
    "\n",
    "$$E(h^{'}_{i}) = \\frac{E(\\xi_{i})}{1-p}h_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import utils as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root='../Datasets/FashionMNIST', train=True, download=True,\n",
    "                                                    transform=transforms.ToTensor())\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root='../Datasets/FashionMNIST', train=False, download=True,\n",
    "                                                   transform=transforms.ToTensor())\n",
    "    return mnist_train, mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist_train, mnist_test = load_dataset()\n",
    "print(len(mnist_train), len(mnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, drop_prob=0.0):\n",
    "    \n",
    "    x = x.float()\n",
    "    \n",
    "    assert 0 <= drop_prob and drop_prob<= 1\n",
    "    keep_prob = 1 - drop_prob  # 1-p\n",
    "    if keep_prob == 0:\n",
    "        return torch.zeros_like(x)\n",
    "    \n",
    "    mask = (torch.rand(x.shape) < keep_prob).float()\n",
    "  \n",
    "    return mask * x / keep_prob\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "tensor([[ 0.,  2.,  0.],\n",
      "        [ 0.,  8., 10.],\n",
      "        [ 0.,  0., 16.],\n",
      "        [18.,  0., 22.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(4,3)\n",
    "print(dropout(x, 0.0))\n",
    "print(dropout(x, 0.5))\n",
    "print(dropout(x, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256\n",
    "\n",
    "\n",
    "w1 = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_hiddens1)), dtype=torch.float, requires_grad=True)\n",
    "b1 = torch.zeros(num_hiddens1, requires_grad=True)\n",
    "w2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1, num_hiddens2)), dtype=torch.float, requires_grad=True)\n",
    "b2 = torch.zeros(num_hiddens2, requires_grad=True)\n",
    "w3 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2, num_outputs)), dtype=torch.float, requires_grad=True)\n",
    "b3 = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "params = [w1, b1, w2, b2, w3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "def linear_regression(x, w, b):\n",
    "    \n",
    "    return torch.mm(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(x, drop_prob=0.0, is_training=True):\n",
    "    \n",
    "    drop_prob = drop_prob if is_training else 0.0\n",
    "    \n",
    "    h1 = linear_regression(x.view(-1, num_inputs), w1, b1).relu()\n",
    "    h1 = dropout(h1, drop_prob)\n",
    "    h2 = linear_regression(h1, w2, b2).relu()\n",
    "    h2 = dropout(h2, drop_prob)\n",
    "    logits = linear_regression(h2, w3, b3)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(net, torch.nn.Module):\n",
    "            net.eval() # 评估模式, 这会关闭dropout\n",
    "            acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            net.train() # 改回训练模式\n",
    "        else: # 自定义的模型\n",
    "            if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                # 将is_training设置成False\n",
    "                acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "            else:\n",
    "                acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.2\n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "drop_prob = 0.5\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params, lr=lr)\n",
    "\n",
    "train_generator = data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_generator = data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "def train():\n",
    "    for epoch in range(num_epochs):\n",
    "        train_acc_sum, train_num = 0., 0\n",
    "        train_loss_sum = 0.0\n",
    "        for x, y in train_generator:\n",
    "            y_pred = net(x, drop_prob, is_training=True)\n",
    "            \n",
    "            # computer loss\n",
    "            l = loss(y_pred, y).sum() \n",
    "            \n",
    "            # clean zero grad\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # compute grad\n",
    "            l.backward()\n",
    "            \n",
    "            # update parameter\n",
    "            optimizer.step()\n",
    "                \n",
    "            train_loss_sum += l.item()\n",
    "            train_acc_sum += (y_pred.argmax(dim=1)==y).float().sum().item() \n",
    "            train_num += x.shape[0]\n",
    "        \n",
    "        # show train log\n",
    "        train_acc = train_acc_sum / train_num\n",
    "        train_loss = train_loss_sum / train_num\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_generator, net)\n",
    "        \n",
    "        print('epoch {} => loss {:.4f}, train acc {:.4f}, test acc {:.4f}'.\n",
    "              format(epoch + 1, train_loss, train_acc, test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 => loss 0.0056, train acc 0.4378, test acc 0.6718\n",
      "epoch 2 => loss 0.0028, train acc 0.7372, test acc 0.7617\n",
      "epoch 3 => loss 0.0023, train acc 0.7912, test acc 0.8011\n",
      "epoch 4 => loss 0.0020, train acc 0.8139, test acc 0.7907\n",
      "epoch 5 => loss 0.0019, train acc 0.8306, test acc 0.8089\n",
      "epoch 6 => loss 0.0018, train acc 0.8357, test acc 0.8320\n",
      "epoch 7 => loss 0.0017, train acc 0.8426, test acc 0.8357\n",
      "epoch 8 => loss 0.0017, train acc 0.8469, test acc 0.8492\n",
      "epoch 9 => loss 0.0016, train acc 0.8538, test acc 0.8528\n",
      "epoch 10 => loss 0.0016, train acc 0.8562, test acc 0.8522\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
